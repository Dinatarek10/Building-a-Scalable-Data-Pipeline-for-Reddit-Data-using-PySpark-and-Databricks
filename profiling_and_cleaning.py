# -*- coding: utf-8 -*-
"""profiling and cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ohPq5H3BgE1kdLsOW6PReI9HEbKByZAX
"""

import pandas as pd

posts_df = pd.read_csv("/content/reddit_posts.csv")
posts_df

comments_df = pd.read_csv("/content/reddit_comments.csv")
comments_df.head()

posts_profiling_report = pd.DataFrame({
    "Column Name": posts_df.columns,
    "Data Type": posts_df.dtypes.values,
    "Null Count": posts_df.isnull().sum().values,
    "Null %": (posts_df.isnull().sum() / len(posts_df) * 100).values.round(2),
    "Distinct Values": [posts_df[col].nunique() for col in posts_df.columns],
    "Most Frequent Value": ["All unique" if posts_df[col].nunique(dropna=True) == len(posts_df[col].dropna())
    else ", ".join(map(str, posts_df[col].mode().tolist())) if not posts_df[col].mode().empty
    else "None"
    for col in posts_df.columns]
})

posts_profiling_report.to_csv("posts_profiling_report.csv", index=False)

comments_profiling_report = pd.DataFrame({
    "Column Name": comments_df.columns,
    "Data Type": comments_df.dtypes.values,
    "Null Count": comments_df.isnull().sum().values,
    "Null %": (comments_df.isnull().sum() / len(comments_df) * 100).values.round(2),
    "Distinct Values": [comments_df[col].nunique() for col in comments_df.columns],
    "Most Frequent Value": ["All unique" if comments_df[col].nunique(dropna=True) == len(comments_df[col].dropna())
    else ", ".join(map(str, comments_df[col].mode().tolist())) if not comments_df[col].mode().empty
    else "None"
    for col in comments_df.columns]
})

comments_profiling_report.to_csv("comments_profiling_report.csv", index=False)

# Drop the selftext column
cleaned_posts_df = posts_df.drop(columns=['selftext'])


!pip install ftfy

import ftfy
import unicodedata

cleaned_posts_df['title'] = posts_df['title'].apply(
    lambda x: unicodedata.normalize("NFKD", ftfy.fix_text(x)).encode("ascii", "ignore").decode("ascii"))

cleaned_posts_df.to_csv("cleaned_posts.csv", index=False)

# Remove rows where 'author' is null
cleaned_comments_df = comments_df.dropna(subset=['author'])

# Clean encoding issues in 'body'
cleaned_comments_df['body'] = cleaned_comments_df['body'].apply(
    lambda x: unicodedata.normalize("NFKD", ftfy.fix_text(x)).encode("ascii", "ignore").decode("ascii"))

#cleaned_comments_df['body'] = cleaned_comments_df['body'].str.replace(',', '', regex=False)
# Remove multiple characters from 'body'
cleaned_comments_df['body'] = cleaned_comments_df['body'].str.replace(
    r'[,\-:>"\n\r]', '', regex=True)

cleaned_comments_df.to_csv("cleaned_comments.csv", index=False)